{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdQLN4OSRflR",
        "outputId": "1cb46691-b6a5-4ce3-ea26-f653391817fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_root='/content/drive/My Drive/chat__bot'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqH4Rf7WSJiu",
        "outputId": "c57d1e56-83e6-4f78-a4bc-412b50f29985"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import string\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3REfLR9SsCM"
      },
      "outputs": [],
      "source": [
        "data_file=open(data_root + '/dataset.json').read()\n",
        "data=json.loads(data_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31PHNUVUTbcg"
      },
      "outputs": [],
      "source": [
        "words=[]\n",
        "classes=[]\n",
        "data_X=[]\n",
        "data_Y=[]\n",
        "\n",
        "for intent in data[\"intents\"]:\n",
        "  for pattern in intent[\"examples\"]:\n",
        "    tokens=nltk.word_tokenize(pattern)\n",
        "    words.extend(tokens)\n",
        "    data_X.append(pattern)\n",
        "    data_Y.append(intent[\"name\"]),\n",
        "  if intent[\"name\"] not in classes:\n",
        "    classes.append(intent[\"name\"])\n",
        "\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "words=[lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
        "words=sorted(set(words))\n",
        "classes=sorted(set(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByjXWNN-Vo44"
      },
      "outputs": [],
      "source": [
        "training=[]\n",
        "out_empty=[0]*len(classes)\n",
        "for idx,doc in enumerate(data_X):\n",
        "  bow=[]\n",
        "  text=lemmatizer.lemmatize(doc.lower())\n",
        "  for word in words:\n",
        "    bow.append(1) if word in text else bow.append(0)\n",
        "  output_row=list(out_empty)\n",
        "  output_row[classes.index(data_Y[idx])]=1\n",
        "  training.append([bow,output_row])\n",
        "random.shuffle(training)\n",
        "training=np.array(training,dtype=object)\n",
        "train_X=np.array(list(training[:,0]))\n",
        "train_Y=np.array(list(training[:,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY8zH4phYen-",
        "outputId": "52c5b839-4f2c-4559-8266-7285b51855ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               7296      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16592 (64.81 KB)\n",
            "Trainable params: 16592 (64.81 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "2/2 [==============================] - 1s 21ms/step - loss: 2.8094 - accuracy: 0.0769\n",
            "Epoch 2/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.7078 - accuracy: 0.0513\n",
            "Epoch 3/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.6078 - accuracy: 0.2051\n",
            "Epoch 4/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.5721 - accuracy: 0.2564\n",
            "Epoch 5/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.4643 - accuracy: 0.2564\n",
            "Epoch 6/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4194 - accuracy: 0.2821\n",
            "Epoch 7/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.2614 - accuracy: 0.3077\n",
            "Epoch 8/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0481 - accuracy: 0.4359\n",
            "Epoch 9/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8958 - accuracy: 0.5128\n",
            "Epoch 10/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7926 - accuracy: 0.5897\n",
            "Epoch 11/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7055 - accuracy: 0.5897\n",
            "Epoch 12/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7892 - accuracy: 0.3333\n",
            "Epoch 13/150\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.5341 - accuracy: 0.6410\n",
            "Epoch 14/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.5219 - accuracy: 0.5385\n",
            "Epoch 15/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0033 - accuracy: 0.7436\n",
            "Epoch 16/150\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1200 - accuracy: 0.7179\n",
            "Epoch 17/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0059 - accuracy: 0.6667\n",
            "Epoch 18/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9394 - accuracy: 0.7179\n",
            "Epoch 19/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8673 - accuracy: 0.7692\n",
            "Epoch 20/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8052 - accuracy: 0.7692\n",
            "Epoch 21/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7692 - accuracy: 0.7692\n",
            "Epoch 22/150\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6469 - accuracy: 0.8205\n",
            "Epoch 23/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5296 - accuracy: 0.8205\n",
            "Epoch 24/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5424 - accuracy: 0.7949\n",
            "Epoch 25/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7175 - accuracy: 0.7692\n",
            "Epoch 26/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4626 - accuracy: 0.8718\n",
            "Epoch 27/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5954 - accuracy: 0.8462\n",
            "Epoch 28/150\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6010 - accuracy: 0.7692\n",
            "Epoch 29/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3310 - accuracy: 0.8718\n",
            "Epoch 30/150\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3462 - accuracy: 0.8974\n",
            "Epoch 31/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4223 - accuracy: 0.8462\n",
            "Epoch 32/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3663 - accuracy: 0.8718\n",
            "Epoch 33/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2947 - accuracy: 0.9231\n",
            "Epoch 34/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2513 - accuracy: 0.8974\n",
            "Epoch 35/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2133 - accuracy: 0.9231\n",
            "Epoch 36/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3590 - accuracy: 0.8462\n",
            "Epoch 37/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5800 - accuracy: 0.7692\n",
            "Epoch 38/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.9231\n",
            "Epoch 39/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2432 - accuracy: 0.8974\n",
            "Epoch 40/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2686 - accuracy: 0.8974\n",
            "Epoch 41/150\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2161 - accuracy: 0.9231\n",
            "Epoch 42/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2973 - accuracy: 0.9231\n",
            "Epoch 43/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3131 - accuracy: 0.9231\n",
            "Epoch 44/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2568 - accuracy: 0.8974\n",
            "Epoch 45/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2968 - accuracy: 0.9487\n",
            "Epoch 46/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4227 - accuracy: 0.8718\n",
            "Epoch 47/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3411 - accuracy: 0.8718\n",
            "Epoch 48/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2155 - accuracy: 0.9231\n",
            "Epoch 49/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2796 - accuracy: 0.9231\n",
            "Epoch 50/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2006 - accuracy: 0.9231\n",
            "Epoch 51/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1870 - accuracy: 0.9744\n",
            "Epoch 52/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3202 - accuracy: 0.8974\n",
            "Epoch 53/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2400 - accuracy: 0.9487\n",
            "Epoch 54/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2406 - accuracy: 0.9487\n",
            "Epoch 55/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2316 - accuracy: 0.8718\n",
            "Epoch 56/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1723 - accuracy: 0.9487\n",
            "Epoch 57/150\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1926 - accuracy: 0.9231\n",
            "Epoch 58/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2168 - accuracy: 0.9487\n",
            "Epoch 59/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1853 - accuracy: 0.9487\n",
            "Epoch 60/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3301 - accuracy: 0.8974\n",
            "Epoch 61/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3278 - accuracy: 0.8718\n",
            "Epoch 62/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2565 - accuracy: 0.9487\n",
            "Epoch 63/150\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3442 - accuracy: 0.8974\n",
            "Epoch 64/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1727 - accuracy: 0.9487\n",
            "Epoch 65/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1802 - accuracy: 0.9744\n",
            "Epoch 66/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2834 - accuracy: 0.8974\n",
            "Epoch 67/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1903 - accuracy: 0.9231\n",
            "Epoch 68/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2457 - accuracy: 0.8974\n",
            "Epoch 69/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2725 - accuracy: 0.8974\n",
            "Epoch 70/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1427 - accuracy: 0.9744\n",
            "Epoch 71/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3977 - accuracy: 0.7949\n",
            "Epoch 72/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1696 - accuracy: 0.9744\n",
            "Epoch 73/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1696 - accuracy: 0.9231\n",
            "Epoch 74/150\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1505 - accuracy: 0.9744\n",
            "Epoch 75/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1723 - accuracy: 0.9744\n",
            "Epoch 76/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1275 - accuracy: 0.9487\n",
            "Epoch 77/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1042 - accuracy: 0.9744\n",
            "Epoch 78/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3037 - accuracy: 0.8974\n",
            "Epoch 79/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1377 - accuracy: 0.9487\n",
            "Epoch 80/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1272 - accuracy: 0.9487\n",
            "Epoch 81/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2038 - accuracy: 0.9231\n",
            "Epoch 82/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2799 - accuracy: 0.8974\n",
            "Epoch 83/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2427 - accuracy: 0.8974\n",
            "Epoch 84/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2188 - accuracy: 0.9487\n",
            "Epoch 85/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1628 - accuracy: 0.9231\n",
            "Epoch 86/150\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2461 - accuracy: 0.8718\n",
            "Epoch 87/150\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1781 - accuracy: 0.8974\n",
            "Epoch 88/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2154 - accuracy: 0.9231\n",
            "Epoch 89/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2657 - accuracy: 0.8462\n",
            "Epoch 90/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1627 - accuracy: 0.9487\n",
            "Epoch 91/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2071 - accuracy: 0.9231\n",
            "Epoch 92/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2598 - accuracy: 0.8974\n",
            "Epoch 93/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1392 - accuracy: 0.9231\n",
            "Epoch 94/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2545 - accuracy: 0.9231\n",
            "Epoch 95/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1233 - accuracy: 0.9744\n",
            "Epoch 96/150\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0938 - accuracy: 0.9487\n",
            "Epoch 97/150\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2437 - accuracy: 0.8974\n",
            "Epoch 98/150\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1006 - accuracy: 0.9744\n",
            "Epoch 99/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9487\n",
            "Epoch 100/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2071 - accuracy: 0.9231\n",
            "Epoch 101/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0863 - accuracy: 0.9744\n",
            "Epoch 102/150\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2052 - accuracy: 0.8974\n",
            "Epoch 103/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1597 - accuracy: 0.8718\n",
            "Epoch 104/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2149 - accuracy: 0.9231\n",
            "Epoch 105/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0908 - accuracy: 1.0000\n",
            "Epoch 106/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1418 - accuracy: 0.9487\n",
            "Epoch 107/150\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2393 - accuracy: 0.8718\n",
            "Epoch 108/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1374 - accuracy: 0.9487\n",
            "Epoch 109/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1976 - accuracy: 0.9231\n",
            "Epoch 110/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1366 - accuracy: 0.9231\n",
            "Epoch 111/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1615 - accuracy: 0.9487\n",
            "Epoch 112/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2270 - accuracy: 0.9231\n",
            "Epoch 113/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0653 - accuracy: 0.9744\n",
            "Epoch 114/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2142 - accuracy: 0.8974\n",
            "Epoch 115/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1756 - accuracy: 0.9231\n",
            "Epoch 116/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1141 - accuracy: 0.9487\n",
            "Epoch 117/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1401 - accuracy: 0.9744\n",
            "Epoch 118/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 0.9487\n",
            "Epoch 119/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0833 - accuracy: 0.9744\n",
            "Epoch 120/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2354 - accuracy: 0.8718\n",
            "Epoch 121/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1197 - accuracy: 0.9231\n",
            "Epoch 122/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2973 - accuracy: 0.9487\n",
            "Epoch 123/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2532 - accuracy: 0.9231\n",
            "Epoch 124/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2110 - accuracy: 0.9487\n",
            "Epoch 125/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0942 - accuracy: 0.9744\n",
            "Epoch 126/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1436 - accuracy: 0.9487\n",
            "Epoch 127/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9744\n",
            "Epoch 128/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0988 - accuracy: 0.9487\n",
            "Epoch 129/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0915 - accuracy: 0.9744\n",
            "Epoch 130/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1117 - accuracy: 0.9487\n",
            "Epoch 131/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1450 - accuracy: 0.9487\n",
            "Epoch 132/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1537 - accuracy: 0.9487\n",
            "Epoch 133/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1960 - accuracy: 0.9487\n",
            "Epoch 134/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0889 - accuracy: 0.9231\n",
            "Epoch 135/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1262 - accuracy: 0.9744\n",
            "Epoch 136/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2360 - accuracy: 0.8462\n",
            "Epoch 137/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1462 - accuracy: 0.9231\n",
            "Epoch 138/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1016 - accuracy: 0.9487\n",
            "Epoch 139/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2120 - accuracy: 0.8974\n",
            "Epoch 140/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1493 - accuracy: 0.9744\n",
            "Epoch 141/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2059 - accuracy: 0.8974\n",
            "Epoch 142/150\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1497 - accuracy: 0.9487\n",
            "Epoch 143/150\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1186 - accuracy: 0.9744\n",
            "Epoch 144/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1342 - accuracy: 0.9231\n",
            "Epoch 145/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0998 - accuracy: 0.9487\n",
            "Epoch 146/150\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 0.9744\n",
            "Epoch 147/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2261 - accuracy: 0.8718\n",
            "Epoch 148/150\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1185 - accuracy: 0.9231\n",
            "Epoch 149/150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1722 - accuracy: 0.9231\n",
            "Epoch 150/150\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1289 - accuracy: 0.9487\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e7cddf374f0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(128,input_shape=(len(train_X[0]),),activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_Y[0]),activation=\"softmax\"))\n",
        "adam=tf.keras.optimizers.legacy.Adam(learning_rate=0.01,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit(x=train_X,y=train_Y,epochs=150,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l54nVUdfZwJa"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  tokens=nltk.word_tokenize(text)\n",
        "  tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYMMKSKCa-ca"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(text,vocab):\n",
        "  tokens=clean_text(text)\n",
        "  bow=[0] *len(vocab)\n",
        "  for w in tokens:\n",
        "    for idx,word in enumerate(vocab):\n",
        "      if word== w:\n",
        "        bow[idx]=1\n",
        "  return np.array(bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wZJfmrIbZGv"
      },
      "outputs": [],
      "source": [
        "def pred_class(text,vocab,labels):\n",
        "  bow=bag_of_words(text,vocab)\n",
        "  result=model.predict(np.array([bow]))[0]\n",
        "  thresh=0.5\n",
        "  y_pred=[[indx,res] for indx,res in enumerate(result) if res > thresh]\n",
        "  y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list=[]\n",
        "  for r in y_pred:\n",
        "    return_list.append(labels[r[0]])\n",
        "  return return_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udSCyJeZciz6"
      },
      "outputs": [],
      "source": [
        "def get_response(intents_list,intents_json):\n",
        "  if len(intents_list)==0:\n",
        "    result = \"Sorry! I don't understand.\"\n",
        "  else:\n",
        "    tag=intents_list[0]\n",
        "    list_of_intents=intents_json[\"intents\"]\n",
        "    for i in list_of_intents:\n",
        "      if i[\"name\"] == tag:\n",
        "        result=random.choice(i[\"responses\"])\n",
        "        break\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "04Z9R0NMfDZ2",
        "outputId": "e07b866a-057a-44f3-b5d1-4b8981e0a50b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Press 0 if you don't want to chat with our ChatBot.\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Hello! How can I assist you today?\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Honey can be as effective as over-the-counter medicines for coughs, especially in children. However, avoid giving it to infants under 1 year due to the risk of food poisoning.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Sorry! I don't understand.\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "A hot bath can provide relief for conditions affecting muscles, bones, and tendons like arthritis, back pain, and joint pain. It promotes blood flow, but avoid excessive heat if you have a skin condition.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Peppermint oil might help with irritable bowel syndrome by reducing symptoms like cramps, bloating, and gas.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Ginger has been traditionally used to alleviate stomachaches, nausea, and menstrual cramps. Yet, it might not suit everyone and could cause digestive issues or interact with certain medications.\n"
          ]
        }
      ],
      "source": [
        "print(\"Press 0 if you don't want to chat with our ChatBot.\")\n",
        "while True:\n",
        "  message=input(\"\")\n",
        "  if message == \"0\":\n",
        "    break\n",
        "  intents=pred_class(message,words,classes)\n",
        "  result=get_response(intents,data)\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKSD_lg0fbiU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}